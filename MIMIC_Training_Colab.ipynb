{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-IV Table2Graph Training Pipeline\n",
    "## Semantic Relationship Detection with GNN\n",
    "\n",
    "This notebook trains the Table2Graph pipeline on MIMIC-IV healthcare data to learn semantic relationships between table columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q sentence-transformers torch-geometric scikit-learn\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/table2graph_checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Checkpoints will be saved to: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Files\n",
    "\n",
    "**Upload these files to Colab:**\n",
    "1. `table2graph_sem.py` - Main pipeline\n",
    "2. `gcn_conv.py` - TableGCN implementation\n",
    "3. `hosp/` folder - MIMIC-IV CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify uploads\n",
    "import os\n",
    "\n",
    "required_files = ['table2graph_sem.py', 'gcn_conv.py']\n",
    "for f in required_files:\n",
    "    if os.path.exists(f'/content/{f}'):\n",
    "        print(f\"✓ {f} found\")\n",
    "    else:\n",
    "        print(f\"✗ {f} MISSING - please upload!\")\n",
    "\n",
    "if os.path.exists('/content/hosp'):\n",
    "    csv_count = len([f for f in os.listdir('/content/hosp') if f.endswith('.csv')])\n",
    "    print(f\"✓ hosp/ folder found with {csv_count} CSV files\")\n",
    "else:\n",
    "    print(\"✗ hosp/ folder MISSING - please upload!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content')\n",
    "\n",
    "from table2graph_sem import (\n",
    "    ColumnContentExtractor,\n",
    "    LightweightFeatureTokenizer,\n",
    "    RelationshipGenerator,\n",
    "    SemanticLabelGenerator,\n",
    "    GraphBuilder,\n",
    "    GNNEdgePredictor,\n",
    "    Table2GraphPipeline\n",
    ")\n",
    "\n",
    "print(\"✓ Pipeline imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MIMIC-IV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_mimic_tables(hosp_dir, max_rows=500):\n",
    "    \"\"\"Load MIMIC-IV tables with row limit for memory management\"\"\"\n",
    "    tables = {}\n",
    "    \n",
    "    csv_files = [f for f in os.listdir(hosp_dir) if f.endswith('.csv')]\n",
    "    print(f\"Found {len(csv_files)} CSV files\\n\")\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        table_name = csv_file.replace('.csv', '')\n",
    "        filepath = os.path.join(hosp_dir, csv_file)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(filepath, nrows=max_rows, low_memory=False)\n",
    "            \n",
    "            # Skip invalid tables\n",
    "            if len(df.columns) < 2 or len(df) == 0:\n",
    "                continue\n",
    "                \n",
    "            tables[table_name] = df\n",
    "            print(f\"  ✓ {table_name}: {df.shape[0]} × {df.shape[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {table_name}: {e}\")\n",
    "    \n",
    "    return tables\n",
    "\n",
    "# Load tables\n",
    "HOSP_DIR = '/content/hosp'\n",
    "tables = load_mimic_tables(HOSP_DIR, max_rows=500)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(tables)} tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = Table2GraphPipeline(embedding_strategy='hybrid')\n",
    "pipeline.initialize_for_training(model_manager=None, node_dim=512)\n",
    "\n",
    "print(\"✓ Pipeline initialized\")\n",
    "print(f\"  - Semantic labels: {pipeline.train_builder.num_classes}\")\n",
    "print(f\"  - Node dimension: 512\")\n",
    "print(f\"  - GNN layers: 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_epochs': 50,\n",
    "    'batch_size': 4,\n",
    "    'early_stopping_patience': 10,\n",
    "    'checkpoint_every': 5,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "table_list = list(tables.values())\n",
    "table_names = list(tables.keys())\n",
    "\n",
    "history = {'epoch': [], 'loss': [], 'accuracy': [], 'time': []}\n",
    "best_accuracy = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"Training on {len(table_list)} tables\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Shuffle tables\n",
    "    indices = np.random.permutation(len(table_list))\n",
    "    shuffled_tables = [table_list[i] for i in indices]\n",
    "    shuffled_names = [table_names[i] for i in indices]\n",
    "    \n",
    "    # Train in batches\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    \n",
    "    for batch_idx in range(0, len(shuffled_tables), CONFIG['batch_size']):\n",
    "        batch_tables = shuffled_tables[batch_idx:batch_idx + CONFIG['batch_size']]\n",
    "        batch_names = shuffled_names[batch_idx:batch_idx + CONFIG['batch_size']]\n",
    "        \n",
    "        try:\n",
    "            avg_loss, avg_accuracy = pipeline.train_epoch(batch_tables)\n",
    "            epoch_losses.append(avg_loss)\n",
    "            epoch_accuracies.append(avg_accuracy)\n",
    "            \n",
    "            print(f\"  Batch {batch_idx//CONFIG['batch_size']+1}: \"\n",
    "                  f\"Loss={avg_loss:.4f}, Acc={avg_accuracy:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Batch failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Epoch summary\n",
    "    if epoch_losses:\n",
    "        epoch_loss = np.mean(epoch_losses)\n",
    "        epoch_accuracy = np.mean(epoch_accuracies)\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        history['epoch'].append(epoch + 1)\n",
    "        history['loss'].append(float(epoch_loss))\n",
    "        history['accuracy'].append(float(epoch_accuracy))\n",
    "        history['time'].append(float(epoch_time))\n",
    "        \n",
    "        print(f\"\\nEpoch Summary: Loss={epoch_loss:.4f}, Acc={epoch_accuracy:.3f}, Time={epoch_time:.2f}s\")\n",
    "        \n",
    "        # Checkpointing\n",
    "        if (epoch + 1) % CONFIG['checkpoint_every'] == 0:\n",
    "            checkpoint_path = f\"{CHECKPOINT_DIR}/checkpoint_epoch_{epoch+1}.pt\"\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': pipeline.predictor.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                'accuracy': epoch_accuracy,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"✓ Checkpoint saved\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if epoch_accuracy > best_accuracy:\n",
    "            best_accuracy = epoch_accuracy\n",
    "            patience_counter = 0\n",
    "            torch.save(pipeline.predictor.state_dict(), f\"{CHECKPOINT_DIR}/best_model.pt\")\n",
    "            print(f\"✓ New best: {best_accuracy:.3f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= CONFIG['early_stopping_patience']:\n",
    "            print(f\"\\n⚠ Early stopping (no improvement for {patience_counter} epochs)\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Training Complete! Best Accuracy: {best_accuracy:.3f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history['epoch'], history['loss'], 'b-', label='Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(history['epoch'], history['accuracy'], 'g-', label='Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{CHECKPOINT_DIR}/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize for testing\n",
    "pipeline.initialize_for_testing()\n",
    "\n",
    "# Test on admissions table\n",
    "test_table = 'admissions'\n",
    "if test_table in tables:\n",
    "    test_df = tables[test_table]\n",
    "    \n",
    "    print(f\"Testing on: {test_table}\")\n",
    "    print(f\"Shape: {test_df.shape}\")\n",
    "    print(f\"Columns: {list(test_df.columns)}\\n\")\n",
    "    \n",
    "    predictions = pipeline.predict_relationships(test_df)\n",
    "    \n",
    "    print(f\"✓ Predicted {len(predictions)} relationships\\n\")\n",
    "    print(\"Top 10 Predictions:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, pred in enumerate(predictions[:10]):\n",
    "        print(f\"{i+1}. {pred['col1']} ↔ {pred['col2']}\")\n",
    "        print(f\"   Label: {pred['predicted_label']}\")\n",
    "        print(f\"   Confidence: {pred['confidence']:.3f}\")\n",
    "        print(f\"   Meaning: {pred['semantic_meaning'][:80]}...\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save training history\n",
    "with open(f'{CHECKPOINT_DIR}/history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "# Save predictions\n",
    "with open(f'{CHECKPOINT_DIR}/predictions_{test_table}.json', 'w') as f:\n",
    "    json.dump(predictions, f, indent=2)\n",
    "\n",
    "print(\"✓ Results exported to Google Drive\")\n",
    "print(f\"  Location: {CHECKPOINT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
