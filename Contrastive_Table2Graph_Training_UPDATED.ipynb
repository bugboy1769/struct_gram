{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Table-to-Graph Learning Pipeline\n",
    "## Table-Question Alignment with InfoNCE Loss\n",
    "\n",
    "This notebook trains a contrastive learning model that:\n",
    "- Encodes table structures as graph embeddings using GNN\n",
    "- Encodes natural language questions using SentenceTransformer  \n",
    "- Aligns table graphs with matching questions using InfoNCE loss\n",
    "- Enables semantic table retrieval given a question\n",
    "\n",
    "**UPDATED**: Now uses shared question encoder for column names (perfect semantic alignment!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q sentence-transformers torch-geometric scikit-learn tqdm\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoint storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/contrastive_table2graph_checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Checkpoints will be saved to: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify required files are uploaded\n",
    "import os\n",
    "\n",
    "required_files = ['contrastive_table2graph.py', 'gcn_conv.py']\n",
    "for f in required_files:\n",
    "    if os.path.exists(f'/content/{f}'):\n",
    "        print(f\"✓ {f} found\")\n",
    "    else:\n",
    "        print(f\"✗ {f} MISSING - please upload!\")\n",
    "\n",
    "# Check for data directory\n",
    "if os.path.exists('/content/data'):\n",
    "    csv_count = len([f for f in os.listdir('/content/data') if f.endswith('.csv')])\n",
    "    print(f\"✓ data/ folder found with {csv_count} CSV files\")\n",
    "else:\n",
    "    print(\"✗ data/ folder MISSING - please upload CSV files!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Import pipeline components\n",
    "from contrastive_table2graph import (\n",
    "    DataProcessor,\n",
    "    ColumnContentExtractor,\n",
    "    LightweightFeatureTokenizer,\n",
    "    RelationshipGenerator,\n",
    "    SemanticLabelGenerator,\n",
    "    GraphBuilder,\n",
    "    QuestionEncoder,\n",
    "    ContrastiveGNNEncoder,\n",
    "    AttentionPooling,\n",
    "    InfoNCELoss,\n",
    "    TableSpecificQuestionGenerator,  # UPDATED: New question generator\n",
    "    TableQuestionDataset,\n",
    "    collate_fn\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "print(\"✓ Pipeline components imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"✓ Random seed set to 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tables_from_directory(data_dir, max_tables=None, max_rows=500):\n",
    "    \"\"\"\n",
    "    Load CSV tables from directory.\n",
    "    \n",
    "    Args:\n",
    "        data_dir: Path to directory with CSV files\n",
    "        max_tables: Max number of tables to load (None = all)\n",
    "        max_rows: Max rows per table (for memory management)\n",
    "    \n",
    "    Returns:\n",
    "        List of (table_name, DataFrame) tuples\n",
    "    \"\"\"\n",
    "    data_path = Path(data_dir)\n",
    "    csv_files = sorted(data_path.glob('*.csv'))\n",
    "    \n",
    "    if max_tables is not None:\n",
    "        csv_files = csv_files[:max_tables]\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files\\n\")\n",
    "    \n",
    "    tables = []\n",
    "    data_processor = DataProcessor()\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        table_name = csv_file.stem\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(csv_file, nrows=max_rows, low_memory=False)\n",
    "            \n",
    "            # Skip invalid tables\n",
    "            if len(df.columns) < 2:\n",
    "                print(f\"  ✗ {table_name}: < 2 columns\")\n",
    "                continue\n",
    "            \n",
    "            if len(df) == 0:\n",
    "                print(f\"  ✗ {table_name}: empty table\")\n",
    "                continue\n",
    "            \n",
    "            # Assign table name for tracking\n",
    "            df.name = table_name\n",
    "            \n",
    "            tables.append((table_name, df))\n",
    "            print(f\"  ✓ {table_name}: {df.shape[0]} × {df.shape[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {table_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return tables\n",
    "\n",
    "# Load tables\n",
    "DATA_DIR = '/content/data'\n",
    "tables = load_tables_from_directory(DATA_DIR, max_tables=50, max_rows=500)\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(tables)} tables successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display table statistics\n",
    "print(\"Table Statistics:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "total_rows = sum(df.shape[0] for _, df in tables)\n",
    "total_cols = sum(df.shape[1] for _, df in tables)\n",
    "avg_rows = total_rows / len(tables)\n",
    "avg_cols = total_cols / len(tables)\n",
    "\n",
    "print(f\"Total tables: {len(tables)}\")\n",
    "print(f\"Total rows: {total_rows:,}\")\n",
    "print(f\"Total columns: {total_cols}\")\n",
    "print(f\"Avg rows per table: {avg_rows:.1f}\")\n",
    "print(f\"Avg columns per table: {avg_cols:.1f}\")\n",
    "\n",
    "print(\"\\nSample Tables:\")\n",
    "for name, df in tables[:5]:\n",
    "    print(f\"  {name}: {df.shape[0]} × {df.shape[1]} - {list(df.columns[:3])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing pipeline components...\\n\")\n",
    "\n",
    "# Device detection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\\n\")\n",
    "\n",
    "# Core components\n",
    "content_extractor = ColumnContentExtractor()\n",
    "print(\"✓ ColumnContentExtractor\")\n",
    "\n",
    "# UPDATED: Removed include_column_names parameter (doesn't exist)\n",
    "feature_tokenizer = LightweightFeatureTokenizer(\n",
    "    embedding_strategy='hybrid'\n",
    ")\n",
    "print(\"✓ LightweightFeatureTokenizer\")\n",
    "print(f\"  - Statistical feature dimension: {feature_tokenizer.feature_dim}\")\n",
    "\n",
    "relationship_generator = RelationshipGenerator()\n",
    "print(\"✓ RelationshipGenerator\")\n",
    "\n",
    "semantic_label_generator = SemanticLabelGenerator()\n",
    "print(\"✓ SemanticLabelGenerator\")\n",
    "\n",
    "# CRITICAL: Initialize question encoder FIRST (will be shared with GraphBuilder)\n",
    "question_encoder = QuestionEncoder(\n",
    "    model_name='all-mpnet-base-v2',\n",
    "    freeze=True\n",
    ").to(device)\n",
    "print(\"\\n✓ QuestionEncoder: all-mpnet-base-v2 (frozen)\")\n",
    "print(f\"  Output dim: {question_encoder.output_dim}\")\n",
    "\n",
    "# UPDATED: GraphBuilder now shares the question encoder for column names\n",
    "# This creates perfect semantic alignment!\n",
    "pyg_converter = GraphBuilder(\n",
    "    content_extractor=content_extractor,\n",
    "    feature_tokenizer=feature_tokenizer,\n",
    "    relationship_generator=relationship_generator,\n",
    "    semantic_label_generator=semantic_label_generator,\n",
    "    mode='train',\n",
    "    use_column_names=True,           # UPDATED: Enable column name embeddings\n",
    "    question_encoder=question_encoder  # UPDATED: Share the question encoder!\n",
    ")\n",
    "print(\"\\n✓ GraphBuilder (PyG converter)\")\n",
    "print(\"  [INFO] Using shared question encoder for column names - perfect semantic alignment!\")\n",
    "\n",
    "# UPDATED: Use TableSpecificQuestionGenerator instead of QuestionGenerator\n",
    "question_generator = TableSpecificQuestionGenerator()\n",
    "print(\"\\n✓ TableSpecificQuestionGenerator\")\n",
    "print(\"  - Generates unique questions per table with column names\")\n",
    "print(\"  - 20 questions per table: 4 column enum + 5 structural + 5 relationship + 3 hybrid + 3 domain\")\n",
    "print(\"  - 25% of questions leverage GNN message passing (relationship-aware)\")\n",
    "\n",
    "print(\"\\n✓ All components initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Question-Table Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating question-table pairs...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract DataFrames\n",
    "table_dfs = [df for _, df in tables]\n",
    "\n",
    "# UPDATED: Use new question generator\n",
    "question_data = question_generator.generate_dataset(\n",
    "    tables=table_dfs,\n",
    "    relationship_generator=relationship_generator,\n",
    "    num_per_table=20  # 20 unique questions per table\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Generated {len(question_data)} question-table pairs\")\n",
    "print(f\"  - All positive pairs (label=1)\")\n",
    "print(f\"  - {len(question_data) / len(table_dfs):.1f} questions per table (avg)\")\n",
    "print(f\"  - Each question mentions specific column names\")\n",
    "print(f\"  - In-batch negatives will be used during training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample questions\n",
    "print(\"\\nSample Questions:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, q_data in enumerate(question_data[:5]):\n",
    "    print(f\"\\n{i+1}. Question: {q_data['question']}\")\n",
    "    print(f\"   Table name: {q_data.get('table_name', 'unknown')}\")\n",
    "    print(f\"   Table shape: {q_data['table'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating datasets...\\n\")\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = TableQuestionDataset(\n",
    "    question_data=question_data,\n",
    "    data_processor=DataProcessor(),\n",
    "    pyg_converter=pyg_converter\n",
    ")\n",
    "\n",
    "# Train/val split (80/20)\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Dataset Splits:\")\n",
    "print(f\"  Train: {len(train_dataset)} pairs ({len(train_dataset)/total_size*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_dataset)} pairs ({len(val_dataset)/total_size*100:.1f}%)\")\n",
    "print(f\"  Total: {total_size} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,  # Colab compatibility\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders Created:\")\n",
    "print(f\"  Train batches: {len(train_loader)} (batch_size={BATCH_SIZE})\")\n",
    "print(f\"  Val batches:   {len(val_loader)} (batch_size={BATCH_SIZE})\")\n",
    "print(f\"\\n  In each batch:\")\n",
    "print(f\"    - {BATCH_SIZE} positive pairs (question[i] ↔ table[i])\")\n",
    "print(f\"    - {BATCH_SIZE * (BATCH_SIZE - 1)} in-batch negative pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize Graph Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nInitializing graph encoder...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# UPDATED: Changed node_dim from 896 to 1280\n",
    "# - 512-d statistical features\n",
    "# - 768-d column name embeddings (from shared all-mpnet-base-v2)\n",
    "# = 1280-d total node features\n",
    "\n",
    "graph_encoder = ContrastiveGNNEncoder(\n",
    "    node_dim=1280,       # UPDATED: Was 896, now 1280 (512 stats + 768 column names)\n",
    "    hidden_dim=1280,     # Keep same to avoid bottleneck\n",
    "    output_dim=768,      # Project to question space\n",
    "    num_layers=2\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in graph_encoder.parameters())\n",
    "trainable_params = sum(p.numel() for p in graph_encoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"✓ ContrastiveGNNEncoder: 2-layer GNN\")\n",
    "print(f\"  Node dim: 1280 (512 statistical + 768 column name semantics)\")\n",
    "print(f\"  Hidden dim: 1280 (preserves all features)\")\n",
    "print(f\"  Output dim: 768 (matches question space)\")\n",
    "print(f\"  Total params: {total_params:,}\")\n",
    "print(f\"  Trainable params: {trainable_params:,}\")\n",
    "\n",
    "# Move to device\n",
    "graph_encoder = graph_encoder.to(device)\n",
    "\n",
    "print(f\"\\n✓ Model moved to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "loss_fn = InfoNCELoss(temperature=0.07)\n",
    "print(f\"✓ InfoNCELoss: temperature=0.07\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    graph_encoder.parameters(),\n",
    "    lr=5e-4,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "print(f\"✓ AdamW optimizer: lr=5e-4, weight_decay=0.01\")\n",
    "\n",
    "# Cosine annealing scheduler\n",
    "num_training_steps = len(train_loader) * 50\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=num_training_steps,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "print(f\"✓ CosineAnnealingLR scheduler: T_max={num_training_steps}, eta_min=1e-6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_epochs': 50,\n",
    "    'gradient_clip': 1.0,\n",
    "    'print_every': 1,\n",
    "    'save_every': 10,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 70)\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_at_k(graph_embeddings, question_embeddings, k=1):\n",
    "    \"\"\"Compute Recall@K for retrieval.\"\"\"\n",
    "    num_questions = question_embeddings.size(0)\n",
    "    \n",
    "    # Similarity matrix\n",
    "    similarity = torch.matmul(question_embeddings, graph_embeddings.T)\n",
    "    \n",
    "    # Top-k indices\n",
    "    _, top_k_indices = torch.topk(similarity, k=min(k, similarity.size(1)), dim=1)\n",
    "    \n",
    "    # Check if correct graph in top-k\n",
    "    correct_indices = torch.arange(num_questions, device=graph_embeddings.device).unsqueeze(1)\n",
    "    \n",
    "    # Check if correct index is in top-k predictions\n",
    "    matches = (top_k_indices == correct_indices).any(dim=1)\n",
    "    recall_at_k = matches.float().mean().item()\n",
    "    \n",
    "    return recall_at_k\n",
    "\n",
    "def train_epoch(graph_encoder, question_encoder, loss_fn, optimizer, scheduler, train_loader, device, config):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    graph_encoder.train()\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in pbar:\n",
    "        batched_graphs = batch['graphs'].to(device)\n",
    "        questions = batch['questions']\n",
    "        \n",
    "        # Forward pass\n",
    "        graph_embeddings = graph_encoder(\n",
    "            batched_graphs,\n",
    "            batch=batched_graphs.batch\n",
    "        )\n",
    "        \n",
    "        question_embeddings = question_encoder(questions)\n",
    "        question_embeddings = question_embeddings.to(device)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(graph_embeddings, question_embeddings)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            graph_encoder.parameters(),\n",
    "            max_norm=config['gradient_clip']\n",
    "        )\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Show current LR in progress bar\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'lr': f'{current_lr:.2e}'})\n",
    "    \n",
    "    avg_loss = epoch_loss / num_batches if num_batches > 0 else 0.0\n",
    "    return avg_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(graph_encoder, question_encoder, loss_fn, val_loader, device):\n",
    "    \"\"\"Validate on validation set.\"\"\"\n",
    "    graph_encoder.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    all_graph_embeddings = []\n",
    "    all_question_embeddings = []\n",
    "    \n",
    "    for batch in val_loader:\n",
    "        batched_graphs = batch['graphs'].to(device)\n",
    "        questions = batch['questions']\n",
    "        \n",
    "        # Forward pass\n",
    "        graph_embeddings = graph_encoder(\n",
    "            batched_graphs,\n",
    "            batch=batched_graphs.batch\n",
    "        )\n",
    "        \n",
    "        question_embeddings = question_encoder(questions)\n",
    "        question_embeddings = question_embeddings.to(device)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(graph_embeddings, question_embeddings)\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Store for recall calculation\n",
    "        all_graph_embeddings.append(graph_embeddings)\n",
    "        all_question_embeddings.append(question_embeddings)\n",
    "    \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0.0\n",
    "    \n",
    "    # Compute Recall@K\n",
    "    graph_embs = torch.cat(all_graph_embeddings, dim=0)\n",
    "    question_embs = torch.cat(all_question_embeddings, dim=0)\n",
    "    \n",
    "    recall_1 = compute_recall_at_k(graph_embs, question_embs, k=1)\n",
    "    recall_5 = compute_recall_at_k(graph_embs, question_embs, k=5)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'recall@1': recall_1,\n",
    "        'recall@5': recall_5\n",
    "    }\n",
    "\n",
    "print(\"✓ Training utilities defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "history = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_recall@1': [],\n",
    "    'val_recall@5': [],\n",
    "    'learning_rate': [],\n",
    "    'time': []\n",
    "}\n",
    "\n",
    "best_recall = 0.0\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(\n",
    "        graph_encoder, question_encoder, loss_fn, optimizer, scheduler,\n",
    "        train_loader, device, CONFIG\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = validate(\n",
    "        graph_encoder, question_encoder, loss_fn, val_loader, device\n",
    "    )\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Record history\n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['train_loss'].append(float(train_loss))\n",
    "    history['val_loss'].append(float(val_metrics['loss']))\n",
    "    history['val_recall@1'].append(float(val_metrics['recall@1']))\n",
    "    history['val_recall@5'].append(float(val_metrics['recall@5']))\n",
    "    history['learning_rate'].append(float(current_lr))\n",
    "    history['time'].append(float(epoch_time))\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % CONFIG['print_every'] == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"  Val Loss:   {val_metrics['loss']:.4f}\")\n",
    "        print(f\"  Recall@1:   {val_metrics['recall@1']:.3f}\")\n",
    "        print(f\"  Recall@5:   {val_metrics['recall@5']:.3f}\")\n",
    "        print(f\"  LR:         {current_lr:.2e}\")\n",
    "        print(f\"  Time:       {epoch_time:.2f}s\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['recall@1'] > best_recall:\n",
    "        best_recall = val_metrics['recall@1']\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'graph_encoder_state': graph_encoder.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict(),\n",
    "            'metrics': val_metrics,\n",
    "        }, f\"{CHECKPOINT_DIR}/best_model.pt\")\n",
    "        print(f\"  ✓ New best model saved (Recall@1: {best_recall:.3f})\")\n",
    "    \n",
    "    # Periodic checkpoint\n",
    "    if (epoch + 1) % CONFIG['save_every'] == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'graph_encoder_state': graph_encoder.state_dict(),\n",
    "            'optimizer_state': optimizer.state_dict(),\n",
    "            'scheduler_state': scheduler.state_dict(),\n",
    "            'metrics': val_metrics,\n",
    "        }, f\"{CHECKPOINT_DIR}/checkpoint_epoch_{epoch+1}.pt\")\n",
    "        print(f\"  ✓ Checkpoint saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Training Complete!\")\n",
    "print(f\"Best Recall@1: {best_recall:.3f}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history['epoch'], history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['epoch'], history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('InfoNCE Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall curves\n",
    "axes[1].plot(history['epoch'], history['val_recall@1'], 'g-', label='Recall@1', linewidth=2)\n",
    "axes[1].plot(history['epoch'], history['val_recall@5'], 'm-', label='Recall@5', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Recall', fontsize=12)\n",
    "axes[1].set_title('Validation Recall Metrics', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{CHECKPOINT_DIR}/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Training curves saved to {CHECKPOINT_DIR}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Table Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(f\"{CHECKPOINT_DIR}/best_model.pt\", map_location=device)\n",
    "graph_encoder.load_state_dict(checkpoint['graph_encoder_state'])\n",
    "graph_encoder.eval()\n",
    "\n",
    "print(f\"✓ Loaded best model (Epoch {checkpoint['epoch']})\")\n",
    "print(f\"  Recall@1: {checkpoint['metrics']['recall@1']:.3f}\")\n",
    "print(f\"  Recall@5: {checkpoint['metrics']['recall@5']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for all tables\n",
    "print(\"\\nGenerating embeddings for all tables...\")\n",
    "\n",
    "table_embeddings_list = []\n",
    "table_names_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for table_name, df in tqdm(tables, desc=\"Encoding tables\"):\n",
    "        # UPDATED: Use build_graph instead of convert_table\n",
    "        pyg_data = pyg_converter.build_graph(df)\n",
    "        pyg_data = pyg_data.to(device)\n",
    "        \n",
    "        # Encode\n",
    "        graph_emb = graph_encoder(pyg_data, batch=None)\n",
    "        \n",
    "        table_embeddings_list.append(graph_emb.cpu())\n",
    "        table_names_list.append(table_name)\n",
    "\n",
    "table_embeddings = torch.cat(table_embeddings_list, dim=0)\n",
    "print(f\"✓ Encoded {len(tables)} tables: {table_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tables(query_question, top_k=5):\n",
    "    \"\"\"\n",
    "    Given a question, retrieve top-k most relevant tables.\n",
    "    \n",
    "    Args:\n",
    "        query_question: Natural language question\n",
    "        top_k: Number of tables to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        List of (table_name, similarity_score) tuples\n",
    "    \"\"\"\n",
    "    # Encode question\n",
    "    with torch.no_grad():\n",
    "        question_emb = question_encoder([query_question])\n",
    "        question_emb = question_emb.to(device)\n",
    "    \n",
    "    # Compute similarities\n",
    "    table_embs_device = table_embeddings.to(device)\n",
    "    similarities = torch.matmul(question_emb, table_embs_device.T).squeeze()\n",
    "    \n",
    "    # Get top-k\n",
    "    top_k_scores, top_k_indices = torch.topk(similarities, k=min(top_k, len(tables)))\n",
    "    \n",
    "    results = []\n",
    "    for score, idx in zip(top_k_scores, top_k_indices):\n",
    "        results.append({\n",
    "            'table_name': table_names_list[idx],\n",
    "            'similarity': score.item(),\n",
    "            'table_shape': tables[idx][1].shape\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✓ Retrieval function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retrieval with column-specific questions\n",
    "test_questions = [\n",
    "    \"Which table contains patient_id and admission_date columns?\",\n",
    "    \"Which table has foreign key hadm_id that references subject_id?\",\n",
    "    \"Which table tracks time intervals between admittime and dischtime?\",\n",
    "    \"Which table pairs measurement valuenum with dimension itemid?\",\n",
    "    \"Which table has temporal columns charttime and storetime?\",\n",
    "    \"Which table uses icustay_id as an identifier?\"\n",
    "]\n",
    "\n",
    "for query in test_questions:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    results = retrieve_tables(query, top_k=5)\n",
    "    \n",
    "    print(\"\\nTop 5 Retrieved Tables:\")\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"{i+1}. {result['table_name']}\")\n",
    "        print(f\"   Similarity: {result['similarity']:.4f}\")\n",
    "        print(f\"   Shape: {result['table_shape']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "with open(f'{CHECKPOINT_DIR}/training_history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"✓ Training history saved\")\n",
    "\n",
    "# Save final metrics\n",
    "final_metrics = {\n",
    "    'best_recall@1': best_recall,\n",
    "    'final_epoch': CONFIG['num_epochs'],\n",
    "    'num_tables': len(tables),\n",
    "    'num_questions': len(question_data),\n",
    "    'train_size': len(train_dataset),\n",
    "    'val_size': len(val_dataset),\n",
    "    'model_params': total_params,\n",
    "    'node_dim': 1280,\n",
    "    'uses_shared_encoder': True,\n",
    "}\n",
    "\n",
    "with open(f'{CHECKPOINT_DIR}/final_metrics.json', 'w') as f:\n",
    "    json.dump(final_metrics, f, indent=2)\n",
    "\n",
    "print(f\"✓ Final metrics saved\")\n",
    "print(f\"\\n✓ All results exported to: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "### Training Complete!\n",
    "\n",
    "**Model**: Contrastive GNN for Table-Question Alignment (UPDATED VERSION)\n",
    "- Architecture: 2-layer GNN + Attention Pooling + Projection Head\n",
    "- Loss: InfoNCE with in-batch negatives\n",
    "- Question Encoder: all-mpnet-base-v2 (frozen, **shared with column name encoder**)\n",
    "- Graph Encoder: Trainable\n",
    "- Node Features: **1280-d** (512 stats + 768 column names from shared encoder)\n",
    "\n",
    "**Key Improvements**:\n",
    "1. ✅ **Shared encoder**: Column names and questions use the SAME encoder → perfect semantic alignment!\n",
    "2. ✅ **Table-specific questions**: Each question mentions specific column names (e.g., \"hadm_id\", \"subject_id\")\n",
    "3. ✅ **Relationship-aware questions**: 25% of questions leverage GNN message passing\n",
    "4. ✅ **No information bottleneck**: hidden_dim=1280 preserves all features\n",
    "\n",
    "**Saved Artifacts**:\n",
    "- `best_model.pt` - Best model checkpoint\n",
    "- `checkpoint_epoch_*.pt` - Periodic checkpoints\n",
    "- `training_curves.png` - Loss and recall curves\n",
    "- `training_history.json` - Complete training history\n",
    "- `final_metrics.json` - Summary statistics\n",
    "\n",
    "**Expected Performance**:\n",
    "- **Old approach**: Recall@1 < 5% (worse than random guessing)\n",
    "- **New approach**: Recall@1 = 60-80% within 10-20 epochs\n",
    "\n",
    "**Why it works better**:\n",
    "- Column name \"hadm_id\" in table embeddings **exactly matches** \"hadm_id\" in question embeddings\n",
    "- No need to learn complex transformations - just learn which columns to attend to\n",
    "- Questions are unique per table → no ambiguous supervision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
